
<!DOCTYPE html><html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.28.1" theme-name="Stellar" theme-version="1.28.1">
  
  <meta name="generator" content="Hexo 7.2.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f9fafb">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  
  <title>Aerial Mapper learning - Hexo</title>

  
    <meta name="description" content="AERIAL MAPPER论文12345   Author &#x3D; &#123;T. Hinzmann, J. L. Schönberger, M. Pollefeys, and R. Siegwart&#125;,   Title &#x3D; &#123;Mapping on the Fly: Real-time 3D Dense Reconstruction, Digital Surface Map an">
<meta property="og:type" content="article">
<meta property="og:title" content="Aerial Mapper learning">
<meta property="og:url" content="http://example.com/2024/05/12/Aerial-Mapper-learning/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="AERIAL MAPPER论文12345   Author &#x3D; &#123;T. Hinzmann, J. L. Schönberger, M. Pollefeys, and R. Siegwart&#125;,   Title &#x3D; &#123;Mapping on the Fly: Real-time 3D Dense Reconstruction, Digital Surface Map an">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-05-12T02:47:10.000Z">
<meta property="article:modified_time" content="2024-05-13T15:54:25.995Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
  
  
  

  <!-- feed -->
  

  <link rel="stylesheet" href="/css/main.css?v=1.28.1">

  

  

  
</head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="undefined" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Hexo</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="Search"></form><div id="search-result"></div><div class="search-no-result">No Results!</div></div>


<nav class="menu dis-select"></nav>
</div>
<div class="widgets">


<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">Recent Update</span></div><div class="widget-body fs14"><a class="item title" href="/2024/05/03/%E6%88%91%E7%9A%84%E4%BA%94%E6%9C%88%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92%E8%AE%A1%E5%88%92/"><span class="title">我的五月工作安排计划</span></a><a class="item title" href="/2024/05/14/%E6%AD%A3%E5%B0%84%E5%BD%B1%E5%83%8F%E6%8B%BC%E6%8E%A5%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"><span class="title">正射影像拼接算法学习</span></a><a class="item title" href="/2024/05/14/ubuntu%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"><span class="title">ubuntu系统安装</span></a><a class="item title" href="/2024/05/14/%E8%88%AA%E7%A9%BA%E4%BA%8B%E6%95%85%E8%B0%83%E6%9F%A5%E8%BD%AF%E4%BB%B6%E6%98%8E%E7%BB%86/"><span class="title">航空事故调查软件明细</span></a><a class="item title" href="/2024/05/14/win10%E8%A3%85%E6%9C%BA%E6%95%99%E7%A8%8B/"><span class="title">win10装机教程</span></a><a class="item title" href="/2024/05/12/Aerial-Mapper-learning/"><span class="title">Aerial Mapper learning</span></a><a class="item title" href="/2024/05/07/%E5%96%B7%E9%9B%BE%E6%A3%80%E6%B5%8B/"><span class="title">喷雾检测</span></a><a class="item title" href="/2024/05/07/Anaconda-pycharm%E5%AE%89%E8%A3%85%E5%8F%8A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"><span class="title">Anaconda pycharm安装及环境配置</span></a><a class="item title" href="/2024/05/07/hexo-%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"><span class="title">hexo 博客搭建</span></a><a class="item title" href="/2024/05/03/%E5%88%A9%E7%94%A8%E6%AD%A3%E8%A7%A3%E6%B3%95%E8%AE%A1%E7%AE%97%E5%8E%9F%E5%A7%8B%E5%9B%BE%E7%89%87%E4%B8%8A%E7%89%A9%E4%BD%93%E7%9A%84%E7%9C%9F%E5%AE%9E%E5%9D%90%E6%A0%87/"><span class="title">利用正解法计算原始图片上物体的真实坐标</span></a></div></widget>
</div>

</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">Home</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">Blog</a></div>
<div class="flex-row" id="post-meta"><span class="text created">Posted on: <time datetime="2024-05-12T02:47:10.000Z">2024-05-12</time></span><span class="sep updated"></span><span class="text updated">Updated on: <time datetime="2024-05-13T15:54:25.995Z">2024-05-13</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>Aerial Mapper learning</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><h1 id="AERIAL-MAPPER"><a href="#AERIAL-MAPPER" class="headerlink" title="AERIAL MAPPER"></a>AERIAL MAPPER</h1><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   Author = &#123;T. Hinzmann, J. L. Schönberger, M. Pollefeys, and R. Siegwart&#125;,</span><br><span class="line">   Title = &#123;Mapping on the Fly: Real-time 3D Dense Reconstruction, Digital Surface Map and Incremental Orthomosaic Generation for Unmanned Aerial Vehicles&#125;,</span><br><span class="line">   Booktitle = &#123;Field and Service Robotics - Results of the 11th International Conference&#125;,</span><br><span class="line">   Year = &#123;2017&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Mapping on the Fly: Real-Time 3D Dense Reconstruction, Digital Surface Map and Incremental Orthomosaic Generation for Unmanned Aerial Vehicles</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">飞行中的测绘：基于无人机的实时3D密集点云重建，数字表面地图和增量正射影像生成。</span><br></pre></td></tr></table></figure>

<p><strong>Abstract</strong> The reduced operational cost and increased robustness of unmanned aerial vehicles has made them a ubiquitous tool in the commercial, industrial and scientiﬁc sector. Especially the ability to map and surveil a large area in a short amount of time makes them interesting for various applications. Generating a map in real-time is essential for ﬁrst response teams in disaster scenarios such as, e.g. earth-quakes, ﬂoods, or avalanches or may help other UAVs to localize without the need of Global Navigation Satellite Systems. For this application, we implemented a map-ping framework that incrementally generates a dense georeferenced 3D point cloud, a digital surface model, and an orthomosaic and we support our design choices with respect to computational costs and its performance in diverse terrain. For accurate estimation of the camera poses, we employ a cost-efﬁcient sensor setup consisting of a monocular visual-inertial camera rig as well as a Global Positioning System receiver, which we fuse using an incremental smoothing algorithm. We validate our mapping framework on a synthetic dataset embedded in a <strong>hardware-in-the-loop</strong> environment and in a real-world experiment using a ﬁxed-wing UAV. Finally, we show that our framework outperforms existing orthomosaic generation methods by an order of magnitude in terms of timing, making real-time reconstruction and orthomosaic generation feasible on board of unmanned aerial vehicles.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">摘要：无人机运营成本的降低和稳健性的提高使其成为商业、工业和科学领域无处不在的工具。特别是在短时间内能够对大范围进行地图绘制和监视的能力，使它们在各种应用中变得有趣。实时生成地图对于灾难场景下的第一响应团队至关重要，比如地震、洪水或雪崩等情况，或者可以帮助其他无人机在不依赖全球导航卫星系统的情况下进行定位。为了这种应用，我们实现了一个地图绘制框架，它逐步生成密集的地理参考的3D点云、数字地表模型和正射影像，并且我们支持我们的设计选择，以考虑计算成本以及在不同地形中的性能。为了准确估计相机的姿态，我们采用了一种成本效益高的传感器设置，包括单目视觉惯性相机组和全球定位系统接收器，我们使用增量平滑算法将它们进行融合。我们验证了我们的映射框架通过将合成数据集嵌入在HIL环境和在一个真实世界的实验使用固定翼无人机。最后，我们展示了我们的框架在时间方面比现有的正射影像生成方法表现出一个数量级的优势，使得无人机上的实时重建和正射影像生成成为可能。</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">介绍无人机的现状，应用。针对应急救援的实时生成地图问题提出了一个地图绘制框架,框架采用了什么技术，，最后有什么提高。 &quot;Hardware-in-the-loop&quot;（HIL）是一种测试和验证技术，通常用于评估控制系统的性能。在这种技术中，正在开发或测试的控制系统与仿真环境中的硬件实体相结合。这些硬件实体可以是传感器、执行器或其他与系统交互的设备。通过将真实的硬件与仿真环境结合起来，可以更准确地评估控制系统的行为，尤其是在实际硬件不可用或成本较高的情况下。</span><br></pre></td></tr></table></figure>

<p>1 Introduction<br>A fast and precise overview of an area is important for first aid teams in disaster scenarios such as earthquakes, floods, or avalanches. In particular, digital surface models (DSM) and orthomosaics are essential tools to support the human operator in<br>quick decision-making. An orthomosaic gives a broad overview of the surroundings and helps the human operator to find regions of interest. Furthermore, orthomosaics enable every agent with a camera to infer its own absolute pose by employing feature<br>extraction or image matching. The orthomosaic can therefore be used to localize the robot and other unmanned aerial vehicles (UAVs) while solely relying on an image stream [1]. An orthomosaic image is obtained by correcting aerial images for perspective and camera distortion using the information about the camera intrinsics and camera poses such that the generated image is true to scale and corresponds to a map projection throughout the image. The task of true orthorectification requires a three-dimensional model of the scenery. This is necessary in order to appropriately map intensities observed by the perspective camera to their location with respect to the orthographic camera. The DSM represents the three-dimensional model in form of a height map and furthermore helps to detect changes in elevation or to plan robot or human missions. The literature distinguishes between a DSM and a digital terrain model (DTM). The DSM includes the earth’s surface and all objects such<br>as buildings and trees on top of it. In contrast, the DTM models the bare earth’s surface. In this publication, we are only interested in generating DSMs.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">对于地震、洪水或雪崩等灾难场景中的急救团队来说，快速、准确地概览某个区域非常重要。特别是，数字表面模型（DSM）和正射影像是支持操作员快速决策的重要工具。特别是，数字地表模型（DSM）和正射影像是支持人类操作员进行快速决策的重要工具。正射影像提供了对周围环境的广泛概述，并帮助人类操作员找到感兴趣的区域。此外，正射影像使得每个带有摄像头的媒介都能通过采用特征提取或图像匹配来推断自己的绝对姿态。因此正射影像可以被用来定位机器人和其他无人机只依赖图像流。正射影像是根据相机的内部参数和相机姿态的信息校正航拍图像的透视和相机畸变而获得的，以便生成的图像符合比例并对应整个图像的地图投影。真正射影像校正的任务需要任务场景的3维模型。这是为了将透视摄像机观察到的强度适当地映射到它们相对于正交摄像机的位置上。数字表面模型以高程图的形式表示了三维模型，此外还有助与检测高程变化，规划机器人或人类任务。本文区分了数字表面模型和数字地形图的差异。数字表面模型包括地球表面以及其上的建筑物和树木等所有物体。相比之下，数字地形图对裸露的地球表面进行建模。本文中，我们只对生成DSM感兴趣。</span><br></pre></td></tr></table></figure>

<p>2 Related Work<br>The literature for creating overview images can be roughly categorized into panorama and mosaic generation where we utilize the distinction from </p>
<p>[2, p.12]: “Panorama is an extension of field of view (FOV) while mosaic is an extension of point of view (POV)”. The mosaic generation can be divided into forward projection, using e.g. homographies or dense point clouds, and backward projection, using e.g. ray tracing in combination with grids or triangle meshes. An overview of the categories is given in Fig. 1. In this publication, we describe and compare a homography-based and point cloud-based forward projection, as well as a batch, and incremental grid-based backward projection approach by analyzing the advantages and disadvantages<br>Real-Time Dense Reconstruction, Digital Surface Map &amp; Incremental Orthomosaics 3 in particular with respect to their real-time capabilities. All of the approaches above are incorporated in our end-to-end mapping framework (cf. Fig. 2) that tightly couples IMU odometry, GPS position and visual cues in a smoothing-based estimator and thus does not detach state estimation from orthomosaic generation. In summary, we claim the following  contributions:</p>
<p>• A real-time incremental end-to-end dense reconstruction and orthomosaic generation framework for UAVs that tightly couples state estimation and seamless mosaic generation.<br>• Most importantly, we propose an incremental grid-based orthomosaic generation algorithm that is suitable for real-time applications in arbirary terrain by considering the surface model and best viewing angle. We validate its performance on a synthetic and real-world dataset with respect to homography-based, point cloud-based, and batch alternatives.<br>• We open-source our framework aerial_mapper consisting of all described DSM and orthomosaic generation approaches. Our framework augments the efficient and modular grid_map library [3] with utilities for georeferenced mapping from aerial views.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2 相关工作</span><br><span class="line"></span><br><span class="line">本文根据“全景图是视野的延伸而投影影像是视点的延伸”这句话可以将创建的概览图像大致分成全景图和投影影像生成。投影影像生成可以分为前方交会，使用像单应性和密集点云的方法。以及后方交会，使用像光线追踪与三角形网格相结合的方法。图1给出了这些类别的概述（如图1所示）。在本出版物中，我们通过分析优缺点来描述和比较基于单应性和基于点云的前向投影以及基于批量和增量网格的后向投影方法。特别是对于实时密集重建、数字地表图和增量正射图3。所有上述方法都纳入了我们的端到端映射框架（参见图2），该框架将IMU航迹、GPS位置和视觉线索紧密耦合在基于平滑的估计器中，因此不会将状态估计与正射图生成分离开来。总之，我们提出了以下贡献：</span><br><span class="line"></span><br><span class="line">• 一个实时的增量式端到端的无人机密集重建和正射图生成框架，紧密耦合状态估计和无缝的拼接生成。 </span><br><span class="line"></span><br><span class="line">• 最重要的是，我们提出了一种增量式基于网格的正射图生成算法，通过考虑表面模型和最佳视角，适用于任意地形的实时应用。我们在合成和真实世界数据集上验证了其性能，相对于基于单应性变换、基于点云和批处理的替代方案。</span><br><span class="line"></span><br><span class="line"> • 我们开源了我们的框架aerial_mapper，包括所有描述的DSM和正射图生成方法。我们的框架通过为地理参考的航空视图提供实用工具，增强了高效和模块化的grid_map库。</span><br></pre></td></tr></table></figure>

<p>2.1 Panorama Generation<br>Many approaches exist to generate a panoramic view given a set of images by applying a homography. Brown et al. presents in [4] an approach to robustly stitch a set of unordered images to a seamless panorama assuming rotations only around the optical axis. The main steps consist of feature extraction, matching in feature space,applying RANSAC and then computing the homography and applying bundle adjustment. Steedly et al. [5] build up on [4] and predict overlapping images more efficiently by utilizing the fact that the video stream is not unordered. Agarwala et al. [6] generate a multi-viewpoint panorama of a street using a homography and Markov Random Field (MRF) optimization. Lagani&#96;ere et al. [7] use homographies to generate bird-eye views for teleoperation of a robot. All of the approaches have in common that they focus on obtaining seamless and visually appealing panoramas or bird-eye views and are not concerned about georeferencing or georeferencing errors. However, stitching using only feature correspondences leads to error accumulation and distorted maps when directly applied to UAVs as demonstrated e.g. in [8, p. 20]. The same is true when only the first image is georeferenced and the subsequent images are incrementally stitched to this reference image.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2.1 全景生成</span><br><span class="line"></span><br><span class="line">存在许多方法可以通过应用单应性变换来生成给定一组图像的全景视图。Brown等人在[4]中提出了一种假设仅围绕光学轴旋转的健壮拼接一组无序图像到无缝全景图像的方法。主要步骤包括特征提取、特征空间匹配、应用RANSAC然后计算单应性变换并应用捆绑调整。Steedly等人[5]在[4]的基础上进行了改进，并通过利用视频流不是无序的事实更有效地预测重叠图像。Agarwala等人[6]利用单应性变换和马尔可夫随机场（MRF）优化生成了街道的多视点全景图。Lagani`ere等人[7]使用单应性变换为机器人的远程操作生成鸟瞰视图。所有这些方法都共同关注于获取无缝且视觉上吸引人的全景图或鸟瞰图，并不关注地理参考或地理参考错误。然而，仅使用特征对应进行拼接会导致错误累积和扭曲的地图，例如直接应用于无人机，如[8，第20页]所示。当仅第一张图像被地理参考时，并且后续图像被逐渐拼接到该参考图像时，情况也是如此。</span><br></pre></td></tr></table></figure>

<p>2.2 Mosaic Generation<br>2.2.1 Forward Projection<br>In UAV applications, where we are rather interested in generating a seamless and georeferenced mosaic, additional sensor measurements are used to obtain camera pose measurements or estimates: Hemerly et al. [9] describe the process of obtaining a single georeferenced image using a UAV. Olawale et al. [10] recover the camera intrinsics and extrinsics using GPS and manually collected ground control points in combination with the commercial photogrammetric software (Agisoft) and generate an orthomosaic. Yahyanejad et al. present in [8, 2] the results of homography-based image mosaicing from sensor data recorded on board of a rotary-wing UAV with a down-looking camera.As presented, many approaches use a camera pose estimate and an image as in-put and then apply a robust but costly feature detection and matching algorithm.For instance, [8, 2] assume noisy IMU and GPS measurements and deal with this Real-Time Dense Reconstruction, Digital Surface Map &amp; Incremental Orthomosaics by designing a quality function that finds a trade-off between geo-referencing error and seamless stitching. In contrast, we do not detach state estimation and orthomosaic generation but fuse GPS and IMU measurements as well as feature tracks in a consistent smoothing-based state estimation. The small offset between images in combination with gyroscope measurements enables fast and subpixel-accurate Lucas-Kanade feature tracking (KLT) [11]. The use of KLT is also supported by the findings in [12] claiming that KLT achieves the best quantitative results in the context of orthomosaic generation. Our philosophy is that accurate and efficient estimation of the camera poses is the backbone of consistent dense 3D reconstruction  and seamless orthomosaic generation. Furthermore, the literature was previously not concerned about presenting runtime results and [12], [2] deplore lack of quantitative performance measures. We tackle this absence of information by presenting the runtime of all methods and an open-source Gazebo-based HIL environment [13]<br>capable of generating synthetic datasets.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2.2 拼接生成</span><br><span class="line"></span><br><span class="line"> 2.2.1 正向投影</span><br><span class="line"></span><br><span class="line"> 在无人机应用中，我们更感兴趣的是生成无缝和地理参考的投影图像，因此会使用额外的传感器测量来获得摄像机姿态测量或估计：Hemerly等人[9]描述了使用无人机获取单个地理参考图像的过程。Olawale等人[10]利用GPS和手动收集的地面控制点，结合商业摄影测量软件（Agisoft）恢复相机的内外参数，并生成正射图。Yahyanejad等人在[8, 2]中展示了基于单应性变换的图像拼接的结果，这些图像来自于一架装有向下看摄像头的旋翼式无人机上的传感器数据。正如所述，许多方法使用相机姿态估计和图像作为输入，然后应用强大但昂贵的特征检测和匹配算法。例如，[8, 2]假设IMU和GPS测量存在噪声，并通过设计一个质量函数来在地理参考错误和无缝拼接之间找到平衡来解决这个实时密集重建、数字地表图和增量正射图的问题。相比之下，我们不会将状态估计和正射图生成分离开来，而是将GPS和IMU测量以及特征轨迹融合在一致的基于平滑的状态估计中。图像之间的小偏移结合陀螺仪测量使得可以快速且亚像素精度的Lucas-Kanade特征跟踪（KLT）[11]成为可能。在[12]中的研究结果也支持了KLT的使用，并声称在正射图生成的背景下，KLT实现了最佳的定量结果。我们的理念是，准确和高效地估计相机姿态是一致的密集三维重建和无缝正射图生成的基础。此外，先前的文献并不关注展示运行时结果，[12]，[2]也抱怨缺乏定量性能指标。我们通过展示所有方法的运行时以及一个能够生成合成数据集的基于Gazebo的开源硬件在环境 [13] 来解决这一信息缺失问题。</span><br></pre></td></tr></table></figure>

<p>2.2.2 Backward Projection<br>Note that none of the homography-based forward projection approaches presented in the previous section employ a DSM as input. In contrast, in order to generate true orthomosaics, [14] employ triangle-based backprojection, also known as ray tracing, in combination with a DSM. Our backprojection approach is very similar to [14] but we utilize a grid of squares to simplify the raytracing process. Furthermore, we present a novel incremental grid-based orthomosaic generation approach to speed up the computation.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">请注意，在前一节介绍的基于单应性变换的正向投影方法中，没有一种方法使用DSM作为输入。相反，为了生成真实的正射图，[14]利用基于三角形的反投影，也称为光线追踪，结合DSM。我们的反投影方法与[14]非常相似，但我们利用一个方格网格来简化光线追踪过程。此外，我们提出了一种新颖的基于增量网格的正射图生成方法，以加速计算。</span><br></pre></td></tr></table></figure>

<p>3 Methodology<br>The methodology section follows the data flow illustrated in Fig. 2: Sec. 3.1 presents the smoothing-based GPS-IMU-Vision fusion. Given the input images and corresponding optimized camera poses, a dense georeferenced point cloud can be generated using planar rectification, as demonstrated in Sec. 3.2. Sec. 3.3 presents how this dense point cloud can be used to generate a DSM by employing inverse distance weighting (IDW). Finally, Sec. 3.4 presents our approaches to generate an orthomosaic from a stream of images, optimized camera poses, and DSM using (a) forward projection and (b) backward projection.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3 方法论</span><br><span class="line">方法论部分遵循图2所示的数据流程：第3.1节介绍了基于平滑的GPS-IMU-Vision融合。给定输入图像和相应的优化摄像机姿态，可以使用平面矫正方法生成密集的地理参考点云，如第3.2节所示。第3.3节介绍了如何利用这个密集的点云来通过逆距离加权法（IDW）生成数字地表模型（DSM）。最后，第3.4节介绍了我们从一系列图像、优化的摄像机姿态和DSM中生成正射图的方法，使用了（a）正向投影和（b）反向投影。</span><br></pre></td></tr></table></figure>

<p>3.1 Multi-Sensor Fusion<br>In this section, we present the core elements of our proposed multi-sensor fusion framework. We distinguish three coordinate systems: the global frame , the camera frame FC, and the body frame FB. To avoid unnecessary conversions due to the vision-based fusion, we choose the Universal Transverse Mercator (UTM) coordinate system where pGB expresses easting, northing, and elevation. We seek to estimate the robot states xR as well as the set of landmarks xL. We define the robot state as: xR :&#x3D;<br><br>pG<br>B qG<br>B vG<br>B ba bg<br><br>where the orientation, position and velocity of the<br>body frame expressed in global coordinates are denoted with qG<br>B , pG<br>B and vG<br>B . The<br>remaining state vector consists of accelerometer bias ba and gyroscope bias bg.dwd</p>
<p>3.1 多传感器融合<br>在这一部分，我们介绍了我们提出的多传感器融合框架的核心元素。我们区分三个坐标系：全局坐标系FG，相机坐标系FC和机体坐标系FB。为了避免由于基于视觉的融合而产生不必要的转换，我们选择了通用横向墨卡托（UTM）坐标系，其中pGB表示东坐标、北坐标和高程。我们试图估计机器人状态xR以及地标集合xL。我们将机器人状态定义为：xR :&#x3D;[ pGB qGB vGB ba bg ] 其中，用qGB、pGB和vGB表示在全局坐标系中表达的机体坐标系的方向、位置和速度。其余的状态向量由加速度计偏置ba和陀螺仪偏置bg组成。</p>
<p>3.1.1 Vision Front-End<br>FAST features [15] are extracted from every input image and tracked from frame to frame using KLT with subpixel refinement. To speed up the tracking process and to avoid outliers, we use the gyroscope of the IMU to predict the location of the pixel in the subsequent image. Furthermore, we employ feature bucketing to guarantee uniformly distributed features across the image for improved vision-based motion estimation. </p>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>License</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">Newer</div><a href="/2024/05/14/win10%E8%A3%85%E6%9C%BA%E6%95%99%E7%A8%8B/">win10装机教程</a></div><div class="item" id="next"><div class="note">Older</div><a href="/2024/05/07/%E5%96%B7%E9%9B%BE%E6%A3%80%E6%B5%8B/">喷雾检测</a></div></section></div>






<footer class="page-footer footnote"><hr><div class="text"><p>本站由 <a href="/">John Doe</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.28.1">Stellar 1.28.1</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">On This Page</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AERIAL-MAPPER"><span class="toc-text">AERIAL MAPPER</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87"><span class="toc-text">论文</span></a></li></ol></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>Scroll to Top</span></a><a class="buttom" onclick="util.scrollComment()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M10.46 1.25h3.08c1.603 0 2.86 0 3.864.095c1.023.098 1.861.3 2.6.752a5.75 5.75 0 0 1 1.899 1.899c.452.738.654 1.577.752 2.6c.095 1.004.095 2.261.095 3.865v1.067c0 1.141 0 2.036-.05 2.759c-.05.735-.153 1.347-.388 1.913a5.75 5.75 0 0 1-3.112 3.112c-.805.334-1.721.408-2.977.43a10.81 10.81 0 0 0-.929.036c-.198.022-.275.054-.32.08c-.047.028-.112.078-.224.232c-.121.166-.258.396-.476.764l-.542.916c-.773 1.307-2.69 1.307-3.464 0l-.542-.916a10.605 10.605 0 0 0-.476-.764c-.112-.154-.177-.204-.224-.232c-.045-.026-.122-.058-.32-.08c-.212-.023-.49-.03-.93-.037c-1.255-.021-2.171-.095-2.976-.429A5.75 5.75 0 0 1 1.688 16.2c-.235-.566-.338-1.178-.389-1.913c-.049-.723-.049-1.618-.049-2.76v-1.066c0-1.604 0-2.86.095-3.865c.098-1.023.3-1.862.752-2.6a5.75 5.75 0 0 1 1.899-1.899c.738-.452 1.577-.654 2.6-.752C7.6 1.25 8.857 1.25 10.461 1.25M6.739 2.839c-.914.087-1.495.253-1.959.537A4.25 4.25 0 0 0 3.376 4.78c-.284.464-.45 1.045-.537 1.96c-.088.924-.089 2.11-.089 3.761v1c0 1.175 0 2.019.046 2.685c.045.659.131 1.089.278 1.441a4.25 4.25 0 0 0 2.3 2.3c.515.214 1.173.294 2.429.316h.031c.398.007.747.013 1.037.045c.311.035.616.104.909.274c.29.17.5.395.682.645c.169.232.342.525.538.856l.559.944a.52.52 0 0 0 .882 0l.559-.944c.196-.331.37-.624.538-.856c.182-.25.392-.476.682-.645c.293-.17.598-.24.909-.274c.29-.032.639-.038 1.037-.045h.032c1.255-.022 1.913-.102 2.428-.316a4.25 4.25 0 0 0 2.3-2.3c.147-.352.233-.782.278-1.441c.046-.666.046-1.51.046-2.685v-1c0-1.651 0-2.837-.089-3.762c-.087-.914-.253-1.495-.537-1.959a4.25 4.25 0 0 0-1.403-1.403c-.464-.284-1.045-.45-1.96-.537c-.924-.088-2.11-.089-3.761-.089h-3c-1.651 0-2.837 0-3.762.089" clip-rule="evenodd"/><path fill="currentColor" d="M9 11a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0"/></svg><span>Join Discussion</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `Just`,
      min: `minutes ago`,
      hour: `hours ago`,
      day: `days ago`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.28.1" async></script>

<!-- optional -->



<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/flying-pages/2.1.2/flying-pages.min.js"></script><script defer src="https://cdn.bootcdn.net/ajax/libs/vanilla-lazyload/17.8.4/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });
</script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.min.css`,
    js: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.umd.min.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || slide.triggerEl.dataset.caption || null
        }
      });
    })
  }
</script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
